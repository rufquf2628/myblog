{"title":"What is Regressor Model","markdown":{"yaml":{"title":"What is Regressor Model","author":"Hangyul Kim","date":"11/27/2023","categories":["ML"],"format":{"html":{"code-fold":false}},"jupyter":"python3"},"headingText":"Types of Linear Regression Model","containsRefs":false,"markdown":"\n\n\nLinear Regression model is a supervised Machine Learning model. It predicts a dependent variable, y, based on an independent variable, X.\nThe relation between X and y becomes a straight line to predict future data point. Because of these trait, it is best to predict continuous data set.\n\n\n\nThere are many types of linear regression model.\n\n### 1. Simple Linear Regression\n\nSimple Linear Regression is a basic machine learning model with only two variables using a straight line. In the equation below, y is a dependent variable, alpha is y-interccept, beta is slope, and X is a independent variable.\n\n$$\ny=\\alpha +\\beta X\n$$\n\nLet's check with actual example.\n\n#### Importing the libraries\n\n```{python}\nimport numpy as np\nimport pandas as pd\n```\n\n#### Importing the dataset\n\nOur dataset is Salary Data which contains the average salary information based on years of experience. In this dataset, our independent variable, X, is a years of experience and our independent variable, y, is a salary.\n\nLet's think about a simple question. Can we predict someone's salary based on his years of experience? Assume that you try to find an employee to work on your company and finally see a suitable candidate who already has work experience of 3.5 years. How much salary you need to pay for him?\n\nLet's use our simple linear regression model to find the suitable salary for him.\n\n```{python}\ndataset1 = pd.read_csv('../dataset/Salary_Data.csv')\ndataset1\n```\n\n```{python}\nX = dataset1.iloc[:, :-1].values\ny = dataset1.iloc[:, -1].values\n```\n\nNow, we split our dataset into test set and train set.\nWe use sklearn train_test_split to manually split dataset.\nThe size of test set gonna be one third of dataset.\n\n```{python}\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=0)\n```\n\n#### Training the Simple Linear Regression model\n\n```{python}\n#| tags: []\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n```\n\nNow, we have our simple linear regression model that is fitted with our training set. We can predict y value by using this regressor model to predict with our test set.\n\n```{python}\ny_pred = regressor.predict(X_test)\n```\n\n#### Visualising the results\n\n```{python}\nimport matplotlib.pyplot as plt\n\nplt.scatter(X_train, y_train, color='red')\nplt.plot(X_train, regressor.predict(X_train), color='blue')\nplt.title('Salary vs Experience (Training set)')\nplt.xlabel('Years of Experience')\nplt.ylabel('Salary')\nplt.show()\n```\n\nThis is our training set result by simple linear regression model. As we seen above, the red scattered points are actual dataset of our training set, and blue straight line is our simple linear equation driven from our model.\n\nWith this equation and graph, we can predict our test set also.\n\n```{python}\nplt.scatter(X_test, y_test, color = 'red')\nplt.plot(X_train, regressor.predict(X_train), color = 'blue')\nplt.title('Salary vs Experience (Test set)')\nplt.xlabel('Years of Experience')\nplt.ylabel('Salary')\nplt.show()\n```\n\nLet's go back to our question. Can we now determine how much salary for the 3.5 years of experience employee?\n\n```{python}\ny_salary = regressor.predict([[3.5]])\nprint(y_salary)\n```\n\nOur regressor model determines to pay him almost 59500 dollar which seems reasonable to both you and him.\n\n### 2. Multiple Linear Regression\n\nNow, let's move on to the other linear regression model, Multiple Linear Regression.\n\nMultiple Linear Regression model predicts the relationship between a dependent variable and \"two or more\" independent variables using a straight line. In the equation below, $y$ is a dependent variable that model gonna predict and $X_1$ ~ $X_n$ are independent variables to make a straight line.\n\n$$\ny=\\alpha +\\beta_1 X_1 +\\beta_2 X_2 +... + \\beta_n X_n\n$$\n\nLet's move on to the actual example.\n\n#### Importing the dataset\n\nSince we already implemented libraries previously, we only need to import the dataset. Our dataset for the multiple linear regression model is the profits of 50 startup companies with their strategies of R&D spend, Administration, Marketing spend, and state. By generating a straight line with these dataset, we can predict a new company's profit with its strategy.\n\n```{python}\ndataset2 = pd.read_csv('../dataset/50_Startups.csv')\ndataset2\n```\n\n```{python}\nX = dataset2.iloc[:, :-1].values\ny = dataset2.iloc[:, -1].values\n```\n\n#### Encoding categorical data\n\nIn the dataset, there is a \"State\" data which consists of three states: New York, California, and Florida. Since a machine learning model only takes numeric data, we need to change this string data into numeric data. Sklearn provides ColumnTransformer and OneHotEncoder libraries to handle this data encoding.\n\n```{python}\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))\n```\n\n```{python}\nprint(X)\n```\n\nAs it shown above, each state data is converted into three columns data.\n\nCalifornia is converted into \"1.0 0.0 0.0\"\n\nFlorida is converted into \"0.0 1.0 0.0\"\n\nNew York is converted into \"0.0 0.0 1.0\"\n\nSo that, our ML model can recognize each states information with these numeric data.\n\n```{python}\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n```\n\n```{python}\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n```\n\n```{python}\ny_pred = regressor.predict(X_test)\nnp.set_printoptions(precision=2)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n```\n\nNow, similar with simple linear regression, we can predict our test set with multiple linear regression model.\n\n","srcMarkdownNoYaml":"\n\n\nLinear Regression model is a supervised Machine Learning model. It predicts a dependent variable, y, based on an independent variable, X.\nThe relation between X and y becomes a straight line to predict future data point. Because of these trait, it is best to predict continuous data set.\n\n\n## Types of Linear Regression Model\n\nThere are many types of linear regression model.\n\n### 1. Simple Linear Regression\n\nSimple Linear Regression is a basic machine learning model with only two variables using a straight line. In the equation below, y is a dependent variable, alpha is y-interccept, beta is slope, and X is a independent variable.\n\n$$\ny=\\alpha +\\beta X\n$$\n\nLet's check with actual example.\n\n#### Importing the libraries\n\n```{python}\nimport numpy as np\nimport pandas as pd\n```\n\n#### Importing the dataset\n\nOur dataset is Salary Data which contains the average salary information based on years of experience. In this dataset, our independent variable, X, is a years of experience and our independent variable, y, is a salary.\n\nLet's think about a simple question. Can we predict someone's salary based on his years of experience? Assume that you try to find an employee to work on your company and finally see a suitable candidate who already has work experience of 3.5 years. How much salary you need to pay for him?\n\nLet's use our simple linear regression model to find the suitable salary for him.\n\n```{python}\ndataset1 = pd.read_csv('../dataset/Salary_Data.csv')\ndataset1\n```\n\n```{python}\nX = dataset1.iloc[:, :-1].values\ny = dataset1.iloc[:, -1].values\n```\n\nNow, we split our dataset into test set and train set.\nWe use sklearn train_test_split to manually split dataset.\nThe size of test set gonna be one third of dataset.\n\n```{python}\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=0)\n```\n\n#### Training the Simple Linear Regression model\n\n```{python}\n#| tags: []\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n```\n\nNow, we have our simple linear regression model that is fitted with our training set. We can predict y value by using this regressor model to predict with our test set.\n\n```{python}\ny_pred = regressor.predict(X_test)\n```\n\n#### Visualising the results\n\n```{python}\nimport matplotlib.pyplot as plt\n\nplt.scatter(X_train, y_train, color='red')\nplt.plot(X_train, regressor.predict(X_train), color='blue')\nplt.title('Salary vs Experience (Training set)')\nplt.xlabel('Years of Experience')\nplt.ylabel('Salary')\nplt.show()\n```\n\nThis is our training set result by simple linear regression model. As we seen above, the red scattered points are actual dataset of our training set, and blue straight line is our simple linear equation driven from our model.\n\nWith this equation and graph, we can predict our test set also.\n\n```{python}\nplt.scatter(X_test, y_test, color = 'red')\nplt.plot(X_train, regressor.predict(X_train), color = 'blue')\nplt.title('Salary vs Experience (Test set)')\nplt.xlabel('Years of Experience')\nplt.ylabel('Salary')\nplt.show()\n```\n\nLet's go back to our question. Can we now determine how much salary for the 3.5 years of experience employee?\n\n```{python}\ny_salary = regressor.predict([[3.5]])\nprint(y_salary)\n```\n\nOur regressor model determines to pay him almost 59500 dollar which seems reasonable to both you and him.\n\n### 2. Multiple Linear Regression\n\nNow, let's move on to the other linear regression model, Multiple Linear Regression.\n\nMultiple Linear Regression model predicts the relationship between a dependent variable and \"two or more\" independent variables using a straight line. In the equation below, $y$ is a dependent variable that model gonna predict and $X_1$ ~ $X_n$ are independent variables to make a straight line.\n\n$$\ny=\\alpha +\\beta_1 X_1 +\\beta_2 X_2 +... + \\beta_n X_n\n$$\n\nLet's move on to the actual example.\n\n#### Importing the dataset\n\nSince we already implemented libraries previously, we only need to import the dataset. Our dataset for the multiple linear regression model is the profits of 50 startup companies with their strategies of R&D spend, Administration, Marketing spend, and state. By generating a straight line with these dataset, we can predict a new company's profit with its strategy.\n\n```{python}\ndataset2 = pd.read_csv('../dataset/50_Startups.csv')\ndataset2\n```\n\n```{python}\nX = dataset2.iloc[:, :-1].values\ny = dataset2.iloc[:, -1].values\n```\n\n#### Encoding categorical data\n\nIn the dataset, there is a \"State\" data which consists of three states: New York, California, and Florida. Since a machine learning model only takes numeric data, we need to change this string data into numeric data. Sklearn provides ColumnTransformer and OneHotEncoder libraries to handle this data encoding.\n\n```{python}\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))\n```\n\n```{python}\nprint(X)\n```\n\nAs it shown above, each state data is converted into three columns data.\n\nCalifornia is converted into \"1.0 0.0 0.0\"\n\nFlorida is converted into \"0.0 1.0 0.0\"\n\nNew York is converted into \"0.0 0.0 1.0\"\n\nSo that, our ML model can recognize each states information with these numeric data.\n\n```{python}\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n```\n\n```{python}\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n```\n\n```{python}\ny_pred = regressor.predict(X_test)\nnp.set_printoptions(precision=2)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n```\n\nNow, similar with simple linear regression, we can predict our test set with multiple linear regression model.\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"output-file":"RegressorModel.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":"theme.css","title-block-banner":false,"author":"Hangyul Kim","page-layout":"article","title":"What is Regressor Model","date":"11/27/2023","categories":["ML"],"jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}