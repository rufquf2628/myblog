{
  "hash": "45f35d91ff8f2634a79fb65595b0f961",
  "result": {
    "markdown": "---\ntitle: 3. What is Regressor Model\nauthor: Hangyul Kim\ndate: 11/27/2023\nformat:\n  html:\n    code-fold: false\n---\n\nLinear Regression model is a supervised Machine Learning model. It predicts a dependent variable, y, based on an independent variable, X.\nThe relation between X and y becomes a straight line to predict future data point. Because of these trait, it is best to predict continuous data set.\n\n\n## Types of Linear Regression Model\n\nThere are many types of linear regression model.\n\n### 1. Simple Linear Regression\n\nSimple Linear Regression is a basic machine learning model with only two variables using a straight line. In the equation below, y is a dependent variable, alpha is y-interccept, beta is slope, and X is a independent variable.\n\n$$\ny=\\alpha +\\beta X\n$$\n\nLet's check with actual example.\n\n#### Importing the libraries\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\n```\n:::\n\n\n#### Importing the dataset\n\nOur dataset is Salary Data which contains the average salary information based on years of experience. In this dataset, our independent variable, X, is a years of experience and our independent variable, y, is a salary.\n\nLet's think about a simple question. Can we predict someone's salary based on his years of experience? Assume that you try to find an employee to work on your company and finally see a suitable candidate who already has work experience of 3.5 years. How much salary you need to pay for him?\n\nLet's use our simple linear regression model to find the suitable salary for him.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndataset1 = pd.read_csv('../dataset/Salary_Data.csv')\ndataset1\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YearsExperience</th>\n      <th>Salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.1</td>\n      <td>39343.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.3</td>\n      <td>46205.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.5</td>\n      <td>37731.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.0</td>\n      <td>43525.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.2</td>\n      <td>39891.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2.9</td>\n      <td>56642.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3.0</td>\n      <td>60150.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3.2</td>\n      <td>54445.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3.2</td>\n      <td>64445.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3.7</td>\n      <td>57189.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3.9</td>\n      <td>63218.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>4.0</td>\n      <td>55794.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>4.0</td>\n      <td>56957.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>4.1</td>\n      <td>57081.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>4.5</td>\n      <td>61111.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>4.9</td>\n      <td>67938.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>5.1</td>\n      <td>66029.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>5.3</td>\n      <td>83088.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>5.9</td>\n      <td>81363.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>6.0</td>\n      <td>93940.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>6.8</td>\n      <td>91738.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>7.1</td>\n      <td>98273.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>7.9</td>\n      <td>101302.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>8.2</td>\n      <td>113812.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>8.7</td>\n      <td>109431.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>9.0</td>\n      <td>105582.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>9.5</td>\n      <td>116969.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>9.6</td>\n      <td>112635.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>10.3</td>\n      <td>122391.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>10.5</td>\n      <td>121872.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nX = dataset1.iloc[:, :-1].values\ny = dataset1.iloc[:, -1].values\n```\n:::\n\n\nNow, we split our dataset into test set and train set.\nWe use sklearn train_test_split to manually split dataset.\nThe size of test set gonna be one third of dataset.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=0)\n```\n:::\n\n\n#### Training the Simple Linear Regression model\n\n::: {.cell tags='[]' execution_count=5}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\nNow, we have our simple linear regression model that is fitted with our training set. We can predict y value by using this regressor model to predict with our test set.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ny_pred = regressor.predict(X_test)\n```\n:::\n\n\n#### Visualising the results\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\nplt.scatter(X_train, y_train, color='red')\nplt.plot(X_train, regressor.predict(X_train), color='blue')\nplt.title('Salary vs Experience (Training set)')\nplt.xlabel('Years of Experience')\nplt.ylabel('Salary')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](RegressorModel_files/figure-html/cell-8-output-1.png){width=619 height=449}\n:::\n:::\n\n\nThis is our training set result by simple linear regression model. As we seen above, the red scattered points are actual dataset of our training set, and blue straight line is our simple linear equation driven from our model.\n\nWith this equation and graph, we can predict our test set also.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nplt.scatter(X_test, y_test, color = 'red')\nplt.plot(X_train, regressor.predict(X_train), color = 'blue')\nplt.title('Salary vs Experience (Test set)')\nplt.xlabel('Years of Experience')\nplt.ylabel('Salary')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](RegressorModel_files/figure-html/cell-9-output-1.png){width=619 height=449}\n:::\n:::\n\n\nLet's go back to our question. Can we now determine how much salary for the 3.5 years of experience employee?\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ny_salary = regressor.predict([[3.5]])\nprint(y_salary)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[59526.99079496]\n```\n:::\n:::\n\n\nOur regressor model determines to pay him almost 59500 dollar which seems reasonable to both you and him.\n\n### 2. Multiple Linear Regression\n\nNow, let's move on to the other linear regression model, Multiple Linear Regression.\n\nMultiple Linear Regression model predicts the relationship between a dependent variable and \"two or more\" independent variables using a straight line. In the equation below, $y$ is a dependent variable that model gonna predict and $X_1$ ~ $X_n$ are independent variables to make a straight line.\n\n$$\ny=\\alpha +\\beta_1 X_1 +\\beta_2 X_2 +... + \\beta_n X_n\n$$\n\nLet's move on to the actual example.\n\n#### Importing the dataset\n\nSince we already implemented libraries previously, we only need to import the dataset. Our dataset for the multiple linear regression model is the profits of 50 startup companies with their strategies of R&D spend, Administration, Marketing spend, and state. By generating a straight line with these dataset, we can predict a new company's profit with its strategy.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\ndataset2 = pd.read_csv('../dataset/50_Startups.csv')\ndataset2\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>R&amp;D Spend</th>\n      <th>Administration</th>\n      <th>Marketing Spend</th>\n      <th>State</th>\n      <th>Profit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>165349.20</td>\n      <td>136897.80</td>\n      <td>471784.10</td>\n      <td>New York</td>\n      <td>192261.83</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>162597.70</td>\n      <td>151377.59</td>\n      <td>443898.53</td>\n      <td>California</td>\n      <td>191792.06</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>153441.51</td>\n      <td>101145.55</td>\n      <td>407934.54</td>\n      <td>Florida</td>\n      <td>191050.39</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>144372.41</td>\n      <td>118671.85</td>\n      <td>383199.62</td>\n      <td>New York</td>\n      <td>182901.99</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>142107.34</td>\n      <td>91391.77</td>\n      <td>366168.42</td>\n      <td>Florida</td>\n      <td>166187.94</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>131876.90</td>\n      <td>99814.71</td>\n      <td>362861.36</td>\n      <td>New York</td>\n      <td>156991.12</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>134615.46</td>\n      <td>147198.87</td>\n      <td>127716.82</td>\n      <td>California</td>\n      <td>156122.51</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>130298.13</td>\n      <td>145530.06</td>\n      <td>323876.68</td>\n      <td>Florida</td>\n      <td>155752.60</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>120542.52</td>\n      <td>148718.95</td>\n      <td>311613.29</td>\n      <td>New York</td>\n      <td>152211.77</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>123334.88</td>\n      <td>108679.17</td>\n      <td>304981.62</td>\n      <td>California</td>\n      <td>149759.96</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>101913.08</td>\n      <td>110594.11</td>\n      <td>229160.95</td>\n      <td>Florida</td>\n      <td>146121.95</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>100671.96</td>\n      <td>91790.61</td>\n      <td>249744.55</td>\n      <td>California</td>\n      <td>144259.40</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>93863.75</td>\n      <td>127320.38</td>\n      <td>249839.44</td>\n      <td>Florida</td>\n      <td>141585.52</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>91992.39</td>\n      <td>135495.07</td>\n      <td>252664.93</td>\n      <td>California</td>\n      <td>134307.35</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>119943.24</td>\n      <td>156547.42</td>\n      <td>256512.92</td>\n      <td>Florida</td>\n      <td>132602.65</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>114523.61</td>\n      <td>122616.84</td>\n      <td>261776.23</td>\n      <td>New York</td>\n      <td>129917.04</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>78013.11</td>\n      <td>121597.55</td>\n      <td>264346.06</td>\n      <td>California</td>\n      <td>126992.93</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>94657.16</td>\n      <td>145077.58</td>\n      <td>282574.31</td>\n      <td>New York</td>\n      <td>125370.37</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>91749.16</td>\n      <td>114175.79</td>\n      <td>294919.57</td>\n      <td>Florida</td>\n      <td>124266.90</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>86419.70</td>\n      <td>153514.11</td>\n      <td>0.00</td>\n      <td>New York</td>\n      <td>122776.86</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>76253.86</td>\n      <td>113867.30</td>\n      <td>298664.47</td>\n      <td>California</td>\n      <td>118474.03</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>78389.47</td>\n      <td>153773.43</td>\n      <td>299737.29</td>\n      <td>New York</td>\n      <td>111313.02</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>73994.56</td>\n      <td>122782.75</td>\n      <td>303319.26</td>\n      <td>Florida</td>\n      <td>110352.25</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>67532.53</td>\n      <td>105751.03</td>\n      <td>304768.73</td>\n      <td>Florida</td>\n      <td>108733.99</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>77044.01</td>\n      <td>99281.34</td>\n      <td>140574.81</td>\n      <td>New York</td>\n      <td>108552.04</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>64664.71</td>\n      <td>139553.16</td>\n      <td>137962.62</td>\n      <td>California</td>\n      <td>107404.34</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>75328.87</td>\n      <td>144135.98</td>\n      <td>134050.07</td>\n      <td>Florida</td>\n      <td>105733.54</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>72107.60</td>\n      <td>127864.55</td>\n      <td>353183.81</td>\n      <td>New York</td>\n      <td>105008.31</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>66051.52</td>\n      <td>182645.56</td>\n      <td>118148.20</td>\n      <td>Florida</td>\n      <td>103282.38</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>65605.48</td>\n      <td>153032.06</td>\n      <td>107138.38</td>\n      <td>New York</td>\n      <td>101004.64</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>61994.48</td>\n      <td>115641.28</td>\n      <td>91131.24</td>\n      <td>Florida</td>\n      <td>99937.59</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>61136.38</td>\n      <td>152701.92</td>\n      <td>88218.23</td>\n      <td>New York</td>\n      <td>97483.56</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>63408.86</td>\n      <td>129219.61</td>\n      <td>46085.25</td>\n      <td>California</td>\n      <td>97427.84</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>55493.95</td>\n      <td>103057.49</td>\n      <td>214634.81</td>\n      <td>Florida</td>\n      <td>96778.92</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>46426.07</td>\n      <td>157693.92</td>\n      <td>210797.67</td>\n      <td>California</td>\n      <td>96712.80</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>46014.02</td>\n      <td>85047.44</td>\n      <td>205517.64</td>\n      <td>New York</td>\n      <td>96479.51</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>28663.76</td>\n      <td>127056.21</td>\n      <td>201126.82</td>\n      <td>Florida</td>\n      <td>90708.19</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>44069.95</td>\n      <td>51283.14</td>\n      <td>197029.42</td>\n      <td>California</td>\n      <td>89949.14</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>20229.59</td>\n      <td>65947.93</td>\n      <td>185265.10</td>\n      <td>New York</td>\n      <td>81229.06</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>38558.51</td>\n      <td>82982.09</td>\n      <td>174999.30</td>\n      <td>California</td>\n      <td>81005.76</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>28754.33</td>\n      <td>118546.05</td>\n      <td>172795.67</td>\n      <td>California</td>\n      <td>78239.91</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>27892.92</td>\n      <td>84710.77</td>\n      <td>164470.71</td>\n      <td>Florida</td>\n      <td>77798.83</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>23640.93</td>\n      <td>96189.63</td>\n      <td>148001.11</td>\n      <td>California</td>\n      <td>71498.49</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>15505.73</td>\n      <td>127382.30</td>\n      <td>35534.17</td>\n      <td>New York</td>\n      <td>69758.98</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>22177.74</td>\n      <td>154806.14</td>\n      <td>28334.72</td>\n      <td>California</td>\n      <td>65200.33</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>1000.23</td>\n      <td>124153.04</td>\n      <td>1903.93</td>\n      <td>New York</td>\n      <td>64926.08</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>1315.46</td>\n      <td>115816.21</td>\n      <td>297114.46</td>\n      <td>Florida</td>\n      <td>49490.75</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>0.00</td>\n      <td>135426.92</td>\n      <td>0.00</td>\n      <td>California</td>\n      <td>42559.73</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>542.05</td>\n      <td>51743.15</td>\n      <td>0.00</td>\n      <td>New York</td>\n      <td>35673.41</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0.00</td>\n      <td>116983.80</td>\n      <td>45173.06</td>\n      <td>California</td>\n      <td>14681.40</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nX = dataset2.iloc[:, :-1].values\ny = dataset2.iloc[:, -1].values\n```\n:::\n\n\n#### Encoding categorical data\n\nIn the dataset, there is a \"State\" data which consists of three states: New York, California, and Florida. Since a machine learning model only takes numeric data, we need to change this string data into numeric data. Sklearn provides ColumnTransformer and OneHotEncoder libraries to handle this data encoding.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))\n```\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nprint(X)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n [0.0 0.0 1.0 86419.7 153514.11 0.0]\n [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n [1.0 0.0 0.0 0.0 135426.92 0.0]\n [0.0 0.0 1.0 542.05 51743.15 0.0]\n [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n```\n:::\n:::\n\n\nAs it shown above, each state data is converted into three columns data.\n\nCalifornia is converted into \"1.0 0.0 0.0\"\n\nFlorida is converted into \"0.0 1.0 0.0\"\n\nNew York is converted into \"0.0 0.0 1.0\"\n\nSo that, our ML model can recognize each states information with these numeric data.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n```\n:::\n\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```{=html}\n<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\ny_pred = regressor.predict(X_test)\nnp.set_printoptions(precision=2)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[103015.2  103282.38]\n [132582.28 144259.4 ]\n [132447.74 146121.95]\n [ 71976.1   77798.83]\n [178537.48 191050.39]\n [116161.24 105008.31]\n [ 67851.69  81229.06]\n [ 98791.73  97483.56]\n [113969.44 110352.25]\n [167921.07 166187.94]]\n```\n:::\n:::\n\n\nNow, similar with simple linear regression, we can predict our test set with multiple linear regression model.\n\n",
    "supporting": [
      "RegressorModel_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}